# [T24.00] OBT Spark: creating OBT dataset

## Documentation:

- [Data warehouse modeling: Star schema vs. OBT](https://www.fivetran.com/blog/star-schema-vs-obt)
- [pyspark.sql.DataFrame.join](https://spark.apache.org/docs/3.1.2/api/python/reference/api/pyspark.sql.DataFrame.join.html)
- [DynamicFrameReader class](https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-crawler-pyspark-extensions-dynamic-frame-reader.html)

## Description:

Create Spark Job that reads fact and dimensions from AWS S3 Analytics bucket. Integrate data and load to AWS S3 Analytics bucket in parquet format to implement OBT logic.

Files for pushing to CodeComet:

- Script name: `obt_analytics_t18.py`

## Configuration:

1. Path: `configurations/obt.yaml`
2. Use `analytics` section
3. Read data from `[data-source][s3]` for fact and dimensions accordingly.
4. Write data to `[data-target][s3][key]`
5. Replace `{user_id}` with your aws account name for target path

## Environment Variables:

- **UserId** = `{user_id}`
- **ConfigBucketKey** = `configurations/{configuration_file_name}.yaml`
- **ConfigBucketName** = `aws-data-engineering-course-{user-id}-assets`

## Local Development:

1. Ingest config file from S3 using commons.
2. Set spark.conf.set("spark.sql.sources.partitionOverwriteMode", "dynamic") option.
3. Read fact data from analytics (source) and obt from analytics (target) zones and find out new data based on ingest_dt column values. You should load only new data to the target.
4. Integrate df from step 3 with dimensions by SK to get all fields from dimensions except ['track_hash', 'record_start_ts', 'record_end_ts', 'record_active_flag', 'record_upd_ts', 'record_insert_ts', 'audit_ts', 'ingest_dt'] if exist.
5. Rename column sk_daily_sales to sk_obt.
6. Drop duplicates and nulls if needed.
7. Add column 'audit_ts' that is equal to current timestamp.
8. Load data to the target with the next schema partitioning by ingest_dt.
```
root
 |-- sk_obt: string (nullable = true)
 |-- sk_order_method: string (nullable = true)
 |-- sk_time_period: string (nullable = true)
 |-- sk_currency: string (nullable = true)
 |-- quantity: integer (nullable = true)
 |-- unit_price: decimal(10,2) (nullable = true)
 |-- unit_sale_price: decimal(10,2) (nullable = true)
 |-- order_method_type: string (nullable = true)
 |-- date: string (nullable = true)
 |-- day_in_week_number: long (nullable = true)
 |-- day_in_week_name: string (nullable = true)
 |-- week_in_quarter_number: long (nullable = true)
 |-- week_in_quarter_name: string (nullable = true)
 |-- week_in_quarter_shortname: string (nullable = true)
 |-- week_in_quarter_year: string (nullable = true)
 |-- week_in_year: long (nullable = true)
 |-- month_number: long (nullable = true)
 |-- month_shortname: string (nullable = true)
 |-- month_in_year: long (nullable = true)
 |-- quarter_number: long (nullable = true)
 |-- quarter_shortname: string (nullable = true)
 |-- quarter_in_year: string (nullable = true)
 |-- half_num: long (nullable = true)
 |-- half_shortname: string (nullable = true)
 |-- half_in_year: string (nullable = true)
 |-- year_number: long (nullable = true)
 |-- year_shortname: string (nullable = true)
 |-- currency_version: integer (nullable = true)
 |-- currency_name: string (nullable = true)
 |-- currency_fullname: string (nullable = true)
 |-- currency_alpha_2: string (nullable = true)
 |-- rate_date: date (nullable = true)
 |-- rate: double (nullable = false)
 |-- base: string (nullable = true)
 |-- audit_ts: timestamp (nullable = false)
 |-- ingest_dt: date (nullable = true)
```