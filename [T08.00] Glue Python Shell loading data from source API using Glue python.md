# [T08.00] Glue Python Shell: loading data from source API using Glue python

## Documentation:

- [AWS::Glue::Job](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-glue-job.html)

## Description:

Create AWS Glue Python Shell Job that ingests API data for currency dim from source to raw zone. **If API is not available use backup data that is stored in S3 in json format (use config to find paths of that data)**.

Files for pushing to CodeComet:

- Script name: `dim_currency_raw_t3.py`
- CloudFormation template: `{user_id}_dim_currency_raw_t3.yaml`

## Configuration:

1. Path: `configurations/dim_currency.yaml`
2. Use `source-to-raw` section
3. Read data from `[data-source][api]` if API is not available use `[data-source][s3][keys][rates]` and write data to `[data-target][s3][keys][rates]`
4. Read data from `[data-source][s3][keys][currency]` and write data to `[data-target][s3][keys][currency]`
5. Replace `{date}` with current date, year with the year of data, {user_id} with your aws account name for target path if it's needed.

## Glue Parameters:

1. To represent Glue Flow developing locally you need to set parameters as it would on the cluster.
2. You can do this with sys.argv.append command before using getResolvedOptions function from awsglue folder in your repository.
3. Parameters that you will need to set:

- **UserId** = `{user_id}`
- **ConfigBucketKey** = `configurations/{configuration_file_name}.yaml`
- **ConfigBucketName** = `aws-data-engineering-course-{user-id}-assets`

## Local Development:

1. Ingest config file from S3 using commons package in your repository.
2. Get API key and url from AWS SecretsManager using SecretId that is stored in config.
3. Get S3 client using commons package.
4. Create list years = [2015, 2016, 2017, 2018] and paste each year in url got from secrets in loop to get data for each year from the source.
5. Write data for rates to the target path.
6. Write data for currency to the target path.
7. If API is not available use backup data that is stored in S3 in json format (use config to find paths of that data).

## Amazon Development:

1. Create a Glue Python Shell on cluster with the name: `{user_id}_dim_currency_raw_t3`.
2. **Mandatory Steps:**
   1. **Choose Python 3.9 for Python version**
   2. **Choose 1/16 DPU for data processing units**
   3. **Choose 0 retries**
   4. **Set timeout for 5**
   5. **Set your bucket path for Script path**
   6. **Set parameters**
   7. **Set Tags Owner=aws-edu-iba-gomel and StudentName={user_id}**
3. Add necessary options to create a Glue Python Shell Job, test a Glue Python Shell Job and check logs in AWS CloudWatch.
4. Create AWS CloudFormation template for Glue Python Shell Job with the name: `{user_id}_dim_currency_raw_t3.yaml`.
5. Test CloudFormation Template:
   1. Deploy (check that your Glue Python Shell has been created using CloudFormation)
   2. Delete your CloudFormation Stack
6. Open Pull Request as described in Common Info (Task Workflow) section.